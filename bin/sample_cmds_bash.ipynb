{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f421346c-3ee2-4498-bad4-fbb55da163f2",
   "metadata": {},
   "source": [
    "# Sample commands for MagellanMapper tasks\n",
    "\n",
    "This notebook demonstrates using MagellanMapper through its command-line interface. You can use the script in various ways:\n",
    "1. Copy the commands to your own Bash shell script\n",
    "1. Modify this notebook with your own image paths and run blocks for your desired tasks\n",
    "\n",
    "**Note**: This notebook is a work-in-progress, migrating commands from the [sample commands script](https://github.com/sanderslab/magellanmapper/blob/master/bin/sample_cmds.sh) to here. Please check back for updates!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b0276-5092-485a-8150-6653cdb19d37",
   "metadata": {},
   "source": [
    "## Prereqs\n",
    "\n",
    "- We assume that you've [installed MagellanMapper](https://github.com/sanderslab/magellanmapper#installation) in a Python environment or from the standalone installer\n",
    "- If you're using a Python environment, activate it (eg `conda activate mag` or `source <path-to-venv>/bin/activate`) before running this Notebook\n",
    "- Paths are relative to the `magellanmapper` folder\n",
    "- Running this Notebook requires [JupyterLab](https://jupyter.org/install) and the [Bash kernel](https://github.com/takluyver/bash_kernel) for Jupyter notebooks, which can be installed by:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ff91655-82d3-4007-8854-fda802a298b9",
   "metadata": {},
   "source": [
    "pip install jupyterlab\n",
    "pip install bash_kernel\n",
    "python -m bash_kernel.install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e9063-6507-499f-b656-1bc166f4dfa6",
   "metadata": {},
   "source": [
    "- Then run JupyterLab:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f28f8b69-fd31-4922-b371-a8e4edfa782d",
   "metadata": {},
   "source": [
    "jupyter-lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d17006-8be2-45c6-87eb-4f666f1cbb6e",
   "metadata": {},
   "source": [
    "## Set up image paths\n",
    "\n",
    "First, let's set up variables to your image paths. The key variable to update is the path to your original image, `img_to_import`. This path minus its extension becomes the \"base path\" that can be used for most commands, including those on downstream output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828db81-6c13-40a0-a2fa-1d3c51f0cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your image file.\n",
    "img_to_import=\"/base/path/to/your/image.czi\"\n",
    "\n",
    "# Main image base path. The \"base path\" is the name of the original image\n",
    "# file without an extension. MagellanMapper typically outputs files named\n",
    "# based on it so that you often only need to specify the base path instead of\n",
    "# exact filenames. For example, after importing img_to_import, the base\n",
    "# path \"/base/path/to/your/image\" can be used for most commands.\n",
    "img=\"${img_to_import%.*}\"\n",
    "\n",
    "# Downsampled image path. The exact path depends on the type of downsampling\n",
    "# performed.\n",
    "img_resized=\"${img}_resized(456,528,320)\"\n",
    "\n",
    "# Atlas profile for registration tasks. Common profiles are \"abaccfv3\" for\n",
    "# the Allen CCFv3 atlas, \"abae18pt5\" for the Allen Developing Mouse Brain E18.5\n",
    "# atlas, and \"whsrat\" for the Waxholm Space rat atlas.\n",
    "reg_profile=abaccfv3\n",
    "\n",
    "# set working directory to MagellanMapper folder\n",
    "if [[ -z \"$BASE_DIR\" ]]; then\n",
    "  BASE_DIR=\"${PWD}/..\"\n",
    "fi\n",
    "cd \"$BASE_DIR\"\n",
    "echo \"Set up paths\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f131f7-fa32-446f-9d27-827e1a400071",
   "metadata": {},
   "source": [
    "## Image import\n",
    "\n",
    "MagellanMapper typically requires images to be imported into a NumPy format (NPY) for faster access and lower memory usage. We use BioFormats to import from many formats, including proprietary microscopy formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69742fb4-d078-4413-b207-3bdc6989237b",
   "metadata": {},
   "source": [
    "### Basic import\n",
    "\n",
    "To import from a microscopy file, we run the `import_only` processing task. It assumes that the image format includes metadata, but you can also specify metadata as below. The `-v` option is for verbose output, which is not necessary but can help with troubleshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861e6d9-982f-4091-8126-db0891c8b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img_to_import\" --proc import_only -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4432e4-087c-4aad-8773-72e9272967cf",
   "metadata": {},
   "source": [
    "### Import with custom metadata\n",
    "\n",
    "You can manually specify metadata, which will take precedence over any corresponding settings discovered in the file. `resolutions` are image resolutions in x,y,z order. `magnification` and `zoom` are microscope objective values. See `--set_meta` in the [CLI reference](https://magellanmapper.readthedocs.io/en/latest/cli.html#command-line-argument-reference) for more metadata options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c83576-782f-4f9d-b123-5246addf84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img_to_import\" --proc import_only -v \\\n",
    "  --set_meta resolutions=10.52,10.52,10 magnification=0.63 zoom=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bafb6e-561f-4faa-b4c0-83a96f6141e1",
   "metadata": {},
   "source": [
    "### Import a series of TIF files\n",
    "<a id=\"import-tif\"></a>\n",
    "\n",
    "Both single- and multi-plane TIF files can be imported into a volumetric NumPy file.\n",
    "\n",
    "To import a series of multi-plane TIF files, their filenames should have the format: `name_ch_0.tif`, `name_ch_1.tif`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392356a2-b043-483c-8f3d-498a1b29b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"${img_to_import%.*}.tif\" --proc import_only -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f4c21-6bae-427a-a3ca-67113425734d",
   "metadata": {},
   "source": [
    "Alternatively, you may have a series of single-plane TIF files. You can put them in a folder and import the whole folder, which will be imported in alphanumerical order. For example, you can import files named: `brain_0000_ch_0.tif`, `brain_0000_ch_1.tif`, `brain_0001_ch_0.tif`, `brain_0001_ch_1.tif`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f64f2-787c-4b80-9276-9e29bf32722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes that img_to_import is a folder containing single-plane TIF files\n",
    "./run.py --img \"$img_to_import\" --proc import_only -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e63e3e-0f1a-4ea7-8863-adb8d8d984a9",
   "metadata": {},
   "source": [
    "To stitch multi-tile images, use the `pipelines.sh` script instead as described below.\n",
    "\n",
    "To view the image after import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e618185-b340-4234-9075-00a9ed83f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7456f-a8ea-45b3-a812-b107d1a273d9",
   "metadata": {},
   "source": [
    "### View a TIF file without import\n",
    "\n",
    "*EXPERIMENTAL*: v1.6 introduced preliminary support for loading TIF files without importing them to NPY format.\n",
    "\n",
    "Bypass import by including the `.tif` extension when loading the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa9bcae-396c-4ebd-a3fe-db22ef976a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm \"${img}.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e10318-4228-4c0f-84f8-4e9485de35a2",
   "metadata": {},
   "source": [
    "To import the TIF file instead, include the `--proc import_only` argument as [above](#import-tif)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7ef87a-2af8-4ceb-86a9-4c73c393cedb",
   "metadata": {},
   "source": [
    "## Atlas Registration\n",
    "\n",
    "MagellanMapper implements the [Elastix](https://elastix.lumc.nl/) registration toolkit (via [SimpleElastix](https://github.com/SuperElastix/SimpleElastix) to align atlases to your samples. Registering an atlas allows analyses of volume, cell counts, etc by anatomical region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15333b-e8db-4ecd-a51b-acc64ddf4179",
   "metadata": {},
   "source": [
    "### Downsample image\n",
    "\n",
    "Microscopy volumetric images are often large, on the scale of hundreds of GBs to TBs. To make these large files more manageable for image registration, we first downsample images to a smaller volume. MagellanMapper resizes images in blocks to reduce memory requirements.\n",
    "\n",
    "To rescale an image by a factor, such as a reduction to 25% of each dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec12c01-e4eb-4413-8903-1a3482608134",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img\" --proc transform --transform rescale=0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074afddc-3061-4448-9be2-d6509844d3e6",
   "metadata": {},
   "source": [
    "To resize to specific dimensions, such as x = 456, y = 528, and z = 320 px:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e1de9-bebf-4cbc-815d-8a1fd92668ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img\" --proc transform --size 456,528,320"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e09bddb-e7bb-4ca1-bcd4-96273a0ffb96",
   "metadata": {},
   "source": [
    "It may be desireable to resize the image to the same size at the atlas. The size of the atlas can be stored in atlas profiles, such as our profile for the CCFv3 atlas set above. Specifying this profile will load the size for downsampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb451bf-be5a-4ba3-ba47-a2ea16b913fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img\" --proc transform --atlas_profile \"$reg_profile\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82817a3e-d390-488e-a97f-4cd2d10bb1c9",
   "metadata": {},
   "source": [
    "You can also transpose the image to another orientation while downsampling. The original orientation is assumed to be XY, while XZ or YZ are the orthogonal dimensions to it. Here, we rescale and tranpose the image to XZ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e16efd-7019-4607-b700-6aeee45277c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img\" --proc transform --transform rescale=0.25 --plane xz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b835e064-22c0-4184-90df-530448e53aa8",
   "metadata": {},
   "source": [
    "To view the downsampled image, we use the name of output file, which is based on type and amount of downsampling. Here, we use the `img_resized` variable set above, which corresponds to downsampling to the atlas image size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c82bc-5664-46ea-8ed3-a1a1f1f53dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img_resized\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195fb19a-fe6c-4ea6-afe1-0070788da70d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Register Atlas to Image\n",
    "\n",
    "Now that we have downsampled our sample image, we can register an atlas to it. Image registration shifts and morphs a \"moving\" image to align it to a \"fixed\" image. To preserve the morphology of the sample image, we make the atlas the \"moving\" image that moves to fit the sample.\n",
    "\n",
    "Let's set up the atlas. The registration toolkit supports 2D to 2D or 3D to 3D image registration. Following the conventions for the Allen Insitute atlases, MagellanMapper will look for an atlas intensity image named `atlasVolume.<ext>`, where `ext` can be any extension supported by ITK, such as MHD, NRRD, and NIFTI. The annotated image should be named `annotation.<ext>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c949bd-2cdb-451f-a842-de9b7afd8052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to atlas directory, assumed to have an atlasVolume and annotation file\n",
    "atlas_dir=\"/path/to/your/atlas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc570f-935c-4004-a9d8-40f3e743ac67",
   "metadata": {},
   "source": [
    "We now register the images by listing the moving image followed by the fixed image.\n",
    "- `single` registration registers single images as opposed to a group of images\n",
    "- `--prefix \"$img\"` outputs image filenames formatted according to the original rather than the resized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a61265-63c5-4ea8-bb5b-d645e9bf9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img_resized\" \"$atlas_dir\" --register single --prefix \"$img\" -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f0954e-b4b1-436b-96c3-90c2f1d7d47d",
   "metadata": {},
   "source": [
    "Atlases are often need reorientation to fit a given sample. Here, we add several example options:\n",
    "- `--transform rotate=2` rotates the atas by 90 deg x2 (= 180 deg) counter-clockwise\n",
    "- `--atlas_profile abaccfv3` uses settings in an atlas profile designed for the Allen CCFv3 atlas\n",
    "- `--channel 1` uses channel 1 (ie the 2nd channel) of the sample for registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfbbff-5065-4904-93cc-b6ebddd047a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img_resized\" \"$atlas_dir\" --register single -v \\\n",
    "  --transform rotate=2 --atlas_profile abaccfv3 --prefix \"$img\" --channel 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7191b3e8-5a55-4cef-bd0d-c4c3813a5d22",
   "metadata": {},
   "source": [
    "To view the registered atlas on the sample, we use the base name of the image and add \"registered image suffixes\" to specify which registered images to load. Registered images use the base image name and add a suffix depending on the image type, such as `_atlasVolume.mhd` and `_annotation.mhd` for the registered atlas intensity and annotation images, respectively. `_exp.mhd` is the same as the sample image.\n",
    "- Registered images suffixes are given as: `--reg_suffixes atlas=<suffix> annotation=<suffix> borders=<suffix> fixed_mask=<suffix> moving_mask=<suffix>`, where the type can be omitted if in the given order\n",
    "- `--roi_profile atlas` can be added to use a grayscale color profile for the intensity image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8cd6d-eb09-4580-acb7-14e375d08f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img\" --reg_suffixes exp.mhd annotation.mhd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5d7fc-e42d-41ed-8b7a-f7cac9ae0426",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cell Detection\n",
    "\n",
    "We use a blob detector to locate cells within an image. This detector identifies areas that are bright compared to their surroundings. We use profiles to adjust parameters for blob sizes, sensitivity thresholds, etc.\n",
    "\n",
    "### Find blobs using the GUI\n",
    "\n",
    "In the \"Detect\" panel, pressing the \"Detect\" button will find all blobs in the current ROI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2653d-494f-45e2-b9c5-089793af2239",
   "metadata": {},
   "source": [
    "### ROI profiles\n",
    "\n",
    "Profiles consist of parameter settings for tasks such as blob detection. We have included a few default profiles, and you can design custom profiles in YAML files. The \"Profiles\" panel in the GUI allows selection and viewing of available profiles.\n",
    "\n",
    "Please see [our docs on profiles](https://magellanmapper.readthedocs.io/en/latest/settings.html#profiles) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b565a31-98eb-482f-841e-6c34082d7fa9",
   "metadata": {},
   "source": [
    "### Find blobs using the CLI\n",
    "\n",
    "To detect blobs in the whole image, using a profile named \"lightsheet\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e822a9b-e441-41af-b746-820b1fcb8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img\" --proc detect --roi_profile lightsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f053b0-3d6d-478f-8349-7fd3b85f43a9",
   "metadata": {},
   "source": [
    "To load these detected blobs instead of re-finding blobs in the given ROI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c06adc-4bbf-4b5d-b58a-cf43a752a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img\" --load blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9eb98f-1850-4764-bc59-e82f282107c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Limit blob detection to an ROI\n",
    "\n",
    "TODO\n",
    "\n",
    "### Volume metrics for each atlas region\n",
    "\n",
    "TODO\n",
    "\n",
    "### Blob colocalization\n",
    "\n",
    "TODO\n",
    "\n",
    "### Build and test ground truth sets\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bedce5-8fec-4310-8d18-f56671eb6f3b",
   "metadata": {},
   "source": [
    "### Classify cells\n",
    "\n",
    "The blob detector identifies objects based on contrast to surrounding areas but cannot distinguish between types of objects. A classifier can help to filter out unwanted detections, such as background noise, or identify different cell types.\n",
    "\n",
    "#### Setup\n",
    "\n",
    "MagellanMapper uses additional dependencies for the classifier, which can be installed with the `classifier` group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e3ee9-e941-4367-a636-46e8615bdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e .[classifier]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa83fc8-792c-4825-aeaf-c7db5c3cfb47",
   "metadata": {},
   "source": [
    "#### Train classifier\n",
    "\n",
    "The classifier trains on labeled images as ground truth. The blob detector can identify objects in your image, which you can label using the annotation tools in the ROI Editor. The classifier learns from these annotations and the images patches around them using a classifier network in Pytorch.\n",
    "\n",
    "TODO\n",
    "\n",
    "#### Apply classifier\n",
    "\n",
    "The trained classifier can be applied to new images through the GUI or CLI.\n",
    "\n",
    "##### GUI\n",
    "\n",
    "1. In the \"Detect\" panel > \"Classifier model\" field, browse to the trained `.h5` classifier model\n",
    "1. Check the desired channels in the \"Chl\" area.\n",
    "1. Presse the \"Detect\" button to detect blobs, which will automatically classify them afterward.\n",
    "\n",
    "Blobs are colored by their class in the ROI Editor. These classes also appear in the \"confirmed\" column of the blobs table.\n",
    "\n",
    "##### CLI\n",
    "\n",
    "To detect and classify blobs, specify the path to your classifier model and run the `detect` task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11156681-0095-47d3-a7e9-07731c998329",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_profile=\"lightsheet\"\n",
    "model_path=\"/path/to/your/model.h5\"\n",
    "mm \"$img\" --roi_profile \"$roi_profile\" --classifier model=\"$model_path\" --proc detect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5414d4b-8739-48d3-becf-c501a8b8ed5b",
   "metadata": {},
   "source": [
    "You can also classify previously detections, which allows repeatedly re-classifying blobs while tweaking the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad6d67-5a91-4b19-a936-728fa8c8e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm \"$img\" --classifier model=\"$model_path\" --proc classify --load blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5362966b-234a-4380-8b73-b57ae646bc64",
   "metadata": {},
   "source": [
    "Load the blobs to view their classifications in the GUI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85448f0-040f-4800-9438-a2a4badd4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm \"$img\" --load blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762cc46-a5b8-4e46-b925-c159762258e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3D Visualization\n",
    "\n",
    "You can render your images as 3D surfaces with spheres for detected cells. MagellanMapper uses VTK in Mayavi to draw and interact with these surfaces in 3D.\n",
    "\n",
    "We typically view these 3D images at several levels:\n",
    "- Downsampled, whole images, since rendering is faster on smaller images\n",
    "- Cell detections on the full-scale image rescaled to fit the downsampled image\n",
    "- Individual brain regions from a registered atlas\n",
    "- ROIs in the full-scale image to view individual microscopic structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e807d2c-d8f3-431d-9035-3888d61507ab",
   "metadata": {},
   "source": [
    "### View full-scale detections on downsampled image\n",
    "\n",
    "To view cell detections, we use a downsampled image to make rendering times manageable. Cells detected in a full-scale image are scaled to the downsampled image and colored according to a registered atlas. This command has these additional components:\n",
    "- `--load blob_matches` loads in match-based colocalizations (optional; can be removed)\n",
    "- `--db <path>` uses a database at a different location, such as one generated on the server where colocalizations were performed (also optional). In this case, we assume that a database file named `magmap.db` is in the image's directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec843a7-a606-4c23-8cc9-431ad6087617",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img\" --roi_profile atlas --reg_suffixes exp.mhd annotation.mhd \\\n",
    "  --load blobs blob_matches -v --db \"$(dirname \"$img\")/magmap.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704c372-ebe7-46e2-9bca-c928eb763f02",
   "metadata": {},
   "source": [
    "Steps after loading the image to render the image:\n",
    "- Set the ROI to contain the whole image by setting the offset to x = 0, y = 0, z = 0, and the size to length of each dimension based on the offset sliders' max values\n",
    "- Leave these default 3D Viewer options checked: raw, surface, no clear\n",
    "- Change to 3D Viewer (may take a few min to render)\n",
    "- Overlay blobs: in the Detect panel, select channel and press Detect\n",
    "- In the Adjust Image panel, reduce the opacity of the main image to see inside the image and start to view blobs inside, which may be very small\n",
    "- Back in the Detect panel, use the \"Scale 3D blobs\" slider to adjust blob sizes as desired. Since each change can take a while, it may be faster to enter a value directly into the text box and press Enter.\n",
    "- Only a fraction of cells are displayed to reduce rendering time. To see a larger proportion of cells, reduce the \"3D blobs mask size\" slider.\n",
    "\n",
    "You can also zoom into the 2D images corresponding to a given cell:\n",
    "- Click on individual blobs to shift the ROI offset to the given blob\n",
    "- Change to the ROI Editor viewer, reduce the ROI size (eg 50,50,10), and press Redraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b1a4fa-5a9e-43fe-8d16-2fc7fbe3a3c2",
   "metadata": {},
   "source": [
    "## Heat Maps\n",
    "\n",
    "Heat or density maps provide another way to visualize whole image cell detections. Cells are grouped into image voxels so that areas of greater cell density are easier to spot as \"hot\" regions. The resulting image is also a downsampled version of the original, making it more compact to load and display."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f890e2ba-1fb9-45a3-8716-22da8402aea4",
   "metadata": {},
   "source": [
    "### Density map for cell detections\n",
    "\n",
    "Generating a cell detection density map will load the blobs file from cell detections for the whole image. By default, the density map will have the same size as that of a registered atlas image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f6230-3811-4c50-9216-553870f113ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py -v --img \"$img\" --register make_density_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f8a32-0393-45d2-9edf-fb4ac787f8ae",
   "metadata": {},
   "source": [
    "To view the image, we set the `heat.mhd` registered image as the main image. We can also overlay the atlas annotations image and use a profile to show high-contrast colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c20f7-fa2d-4eff-9faa-77cdc6cfff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py --img \"$img\" --reg_suffixes heat.mhd annotation.mhd --roi_profile contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e10f3-4fb0-47e1-9303-043d5c72078d",
   "metadata": {},
   "source": [
    "By default, the heat map combines cells from all channels in the image. Use the channel parameter to specify a single or combination of channels. For example, to combine only channels 1 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e78e9-8ad2-45c6-9eea-ca142bc43e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py -v --img \"$img\" --register make_density_images --channel 1 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ec935-5a2c-476f-a72d-9c238f5df83f",
   "metadata": {},
   "source": [
    "To change the size, provide an alternate shape in `x,y,z` order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d7ed4f-4a6a-47d3-93e4-63ef043f5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "./run.py -v --img \"$img\" --register make_density_images --size 200,250,150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59ec5e-3236-459e-a54a-212b11bb8d96",
   "metadata": {},
   "source": [
    "## Export Images\n",
    "\n",
    "TODO\n",
    "\n",
    "## Image Transformations\n",
    "\n",
    "TODO\n",
    "\n",
    "## Generate a new atlas\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
